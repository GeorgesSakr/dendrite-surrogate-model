{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9464478f",
   "metadata": {},
   "source": [
    "**CNN MODEL and Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a02cd",
   "metadata": {},
   "source": [
    "DATA SET LOADER: Same one as the one before, this one loads the training set: Please change the directory to where the splitted files are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7acdea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([8, 5])\n",
      "Target batch shape: torch.Size([8, 30, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "DATASET_DIR = rDATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\Splitting 30 Frames\"\n",
    " # Adjust if needed\n",
    "\n",
    "class DendriteDataset(Dataset):\n",
    "    def __init__(self, split=\"train\"):\n",
    "        assert split in [\"train\", \"val\", \"test\"], \"Split must be 'train', 'val', or 'test'.\"\n",
    "\n",
    "        self.X = np.load(os.path.join(DATASET_DIR, f\"X_{split}.npy\"))\n",
    "        self.Y = np.load(os.path.join(DATASET_DIR, f\"Y_{split}.npy\"))\n",
    "\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(self.Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]           # Shape: (5,)\n",
    "        y = self.Y[idx]           # Shape: (41, 250, 250)\n",
    "        return x, y\n",
    "\n",
    "# === Usage example ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Create datasets\n",
    "    train_dataset = DendriteDataset(split=\"train\")\n",
    "    val_dataset = DendriteDataset(split=\"val\")\n",
    "    test_dataset = DendriteDataset(split=\"test\")\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Quick check\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        print(f\"Input batch shape: {inputs.shape}\")   # Should be (batch_size, 5)\n",
    "        print(f\"Target batch shape: {targets.shape}\") # Should be (batch_size, 41, 250, 250)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15197485",
   "metadata": {},
   "source": [
    "**CNN Class:** 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d75dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeeperCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeeperCNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(5, 128)\n",
    "        self.fc2 = nn.Linear(128, 512)\n",
    "        self.fc3 = nn.Linear(512, 30 * 64 * 64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(30, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 30, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upsample = nn.Upsample(size=(250, 250), mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x, capture_features=False):\n",
    "        features = []\n",
    "\n",
    "        # ‚Äî Global MLP projection to (batch,30*64*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1,30,64,64)\n",
    "\n",
    "        # ‚Äî Capture the *true* time‚Äêframes (coarse)\n",
    "        if capture_features:\n",
    "            features.append(x.clone().detach())\n",
    "\n",
    "        # ‚Äî Then your convolutions (abstract feature‚Äêmaps)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        if capture_features: features.append(x.clone().detach())\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        if capture_features: features.append(x.clone().detach())\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        if capture_features: features.append(x.clone().detach())\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        if capture_features: features.append(x.clone().detach())\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        if capture_features: features.append(x.clone().detach())\n",
    "\n",
    "        # ‚Äî Upsample\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        if capture_features:\n",
    "            return x, features\n",
    "        else:\n",
    "            return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9020262",
   "metadata": {},
   "source": [
    "Data Training: 200 epochs and chooses the one with the lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "DATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\Splitting 30 Frames\"\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 200  # üî• Increased to 200 epochs\n",
    "SAVE_MODEL_PATH = \"best_model_30frames.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load datasets ===\n",
    "train_dataset = DendriteDataset(split=\"train\")\n",
    "val_dataset = DendriteDataset(split=\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# === Initialize model, loss, optimizer ===\n",
    "model = DeeperCNN().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# üî• Add learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "# === Training loop ===\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {train_loss:.6f} - Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # === Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), SAVE_MODEL_PATH)\n",
    "        print(f\"‚úÖ New best model saved at epoch {epoch+1}!\")\n",
    "\n",
    "    # üî• Step the scheduler after every epoch\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"‚úÖ Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63200e",
   "metadata": {},
   "source": [
    "**EVALUATION!**: Calculates MSE on evaluation and plots/saves them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea971eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final Test MSE Loss: 0.017701\n"
     ]
    }
   ],
   "source": [
    "# evaluation_cnn.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # ‚úÖ Add this line\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# === Configurations ===\n",
    "DATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\Splitting 30 Frames\"\n",
    "BATCH_SIZE = 8\n",
    "MODEL_PATH = r\"C:\\Users\\Ali\\Desktop\\798 Project\\visualization_samples_30frames_CNN_DEEP\\best_model_30frames_200Epochs.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_PLOTS_DIR = \"evaluation_plots\"\n",
    "\n",
    "# === Load test dataset ===\n",
    "test_dataset = DendriteDataset(split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# === Load model ===\n",
    "model = DeeperCNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Define loss function ===\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# === Evaluation ===\n",
    "test_loss = 0.0\n",
    "\n",
    "os.makedirs(SAVE_PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Save a few sample plots\n",
    "        if batch_idx < 3:  # Save first 3 batches (can adjust)\n",
    "            for i in range(min(inputs.size(0), 3)):  # Save 3 samples per batch\n",
    "                pred = outputs[i, -1, :, :].cpu().numpy()\n",
    "                true = targets[i, -1, :, :].cpu().numpy()\n",
    "\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                axes[0].imshow(true, cmap=\"plasma\", origin=\"lower\")\n",
    "                axes[0].set_title(\"Ground Truth\")\n",
    "                axes[1].imshow(pred, cmap=\"plasma\", origin=\"lower\")\n",
    "                axes[1].set_title(\"Prediction\")\n",
    "                plt.suptitle(f\"Sample {batch_idx * BATCH_SIZE + i}\")\n",
    "                plt.savefig(os.path.join(SAVE_PLOTS_DIR, f\"sample_{batch_idx * BATCH_SIZE + i}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"‚úÖ Final Test MSE Loss: {test_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9e952",
   "metadata": {},
   "source": [
    "**VISUALIZATION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6735c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Visualization saved in visualization_samples_30frames_deepCNN/\n"
     ]
    }
   ],
   "source": [
    "# visualize_predictions_30frames.py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === Configurations ===\n",
    "DATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\Splitting 30 Frames\"\n",
    "BATCH_SIZE = 1  # Plot one sample at a time\n",
    "MODEL_PATH = r\"C:\\Users\\Ali\\Desktop\\798 Project\\visualization_samples_30frames_CNN_DEEP\\best_model_30frames_200Epochs.pth\"  # Update if you saved with a different name\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_DIR = \"visualization_samples_30frames_deepCNN\"\n",
    "\n",
    "# === Prepare directories ===\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# === Load dataset and model ===\n",
    "test_dataset = DendriteDataset(split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = DeeperCNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Visualize few samples ===\n",
    "frames_to_plot = [0, 5, 10, 20, 29]  # 0 to 29 now (not 39 anymore)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        if batch_idx >= 10:  # Plot 3 samples only\n",
    "            break\n",
    "\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        input_params = inputs.cpu().numpy()[0]\n",
    "        pred = outputs.squeeze(0).cpu().numpy()   # (30, 250, 250)\n",
    "        true = targets.squeeze(0).cpu().numpy()    # (30, 250, 250)\n",
    "\n",
    "        # Plot selected frames\n",
    "        fig, axs = plt.subplots(len(frames_to_plot), 2, figsize=(8, 2.5 * len(frames_to_plot)))\n",
    "\n",
    "        for idx, t in enumerate(frames_to_plot):\n",
    "            axs[idx, 0].imshow(true[t], cmap=\"plasma\", origin=\"lower\", vmin=0, vmax=1)\n",
    "            axs[idx, 0].set_title(f\"Ground Truth (t={t})\")\n",
    "            axs[idx, 0].axis('off')\n",
    "\n",
    "            axs[idx, 1].imshow(pred[t], cmap=\"plasma\", origin=\"lower\", vmin=0, vmax=1)\n",
    "            axs[idx, 1].set_title(f\"Prediction (t={t})\")\n",
    "            axs[idx, 1].axis('off')\n",
    "\n",
    "        plt.suptitle(f\"Sample {batch_idx} | Input: {input_params}\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(SAVE_DIR, f\"sample_{batch_idx}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "print(f\"‚úÖ Visualization saved in {SAVE_DIR}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99b331",
   "metadata": {},
   "source": [
    "VIDEOS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdf1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "# === Config ===\n",
    "SAVE_DIR = \"growth_videos\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Update the MODEL_PATH to your actual model path\n",
    "MODEL_PATH = r\"C:\\Users\\Ali\\Desktop\\798 Project\\visualization_samples_30frames_CNN_DEEP\\best_model_30frames_200Epochs.pth\"\n",
    "\n",
    "# === Load model and dataset ===\n",
    "model = DeeperCNN().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = DendriteDataset(split=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# === Loop through a few samples ===\n",
    "for idx, (inputs, targets) in enumerate(tqdm(test_loader)):\n",
    "    if idx >= 5:\n",
    "        break\n",
    "\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    true = targets.squeeze(0).cpu().numpy()\n",
    "    pred = outputs.squeeze(0).cpu().numpy()\n",
    "\n",
    "    frames = []\n",
    "    for t in range(true.shape[0]):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "        canvas = FigureCanvas(fig)\n",
    "\n",
    "        axs[0].imshow(true[t], cmap='plasma', origin='lower', vmin=0, vmax=1)\n",
    "        axs[0].set_title(f\"Ground Truth t={t}\")\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        axs[1].imshow(pred[t], cmap='plasma', origin='lower', vmin=0, vmax=1)\n",
    "        axs[1].set_title(f\"Prediction t={t}\")\n",
    "        axs[1].axis('off')\n",
    "\n",
    "        canvas.draw()\n",
    "        # Use buffer_rgba to get the image data\n",
    "        w, h = canvas.get_width_height()\n",
    "        buf = canvas.buffer_rgba()\n",
    "        img_arr = np.frombuffer(buf, dtype=np.uint8).reshape(h, w, 4)\n",
    "        # Drop alpha channel\n",
    "        rgb = img_arr[:, :, :3]\n",
    "        frames.append(rgb)\n",
    "        plt.close(fig)\n",
    "\n",
    "    gif_path = os.path.join(SAVE_DIR, f\"sample_{idx}_fixed.gif\")\n",
    "    imageio.mimsave(gif_path, frames, fps=5)\n",
    "    print(f\"üé• Saved: {gif_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
